{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4030697c",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Data Merging & Cleaning â€“ Yousra Descriptive Stats Notebook\n",
    "\n",
    "This notebook loads the original project datasets (sales, weather, kiwo event),  \n",
    "cleans and standardizes the date format, merges them using a full outer join,  \n",
    "and performs descriptive statistics, missing value inspection, and prepares the  \n",
    "data for further feature engineering and modeling.\n",
    "\n",
    "The goal is to:\n",
    "1. Combine **all available data** on matching dates  \n",
    "2. Perform a clear descriptive exploration  \n",
    "3. Detect and handle missing values  \n",
    "4. Produce a clean dataset ready for analysis  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from your project folder\n",
    "df_sales = pd.read_csv(\"data/kiwo.csv\")\n",
    "df_weather = pd.read_csv(\"data/wetter.csv\")\n",
    "df_umsatz = pd.read_csv(\"data/umsatzdaten_gekuerzt.csv\")\n",
    "\n",
    "df_sales.head(), df_weather.head(), df_umsatz.head()\n",
    "#print number of rows for each dataframe\n",
    "print(f\"Sales Data Rows: {len(df_sales)}\")\n",
    "print(f\"Weather Data Rows: {len(df_weather)}\")\n",
    "print(f\"Umsatz Data Rows: {len(df_umsatz)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Datum' to proper datetime format and drop invalid rows\n",
    "for df in (df_sales, df_weather, df_umsatz):\n",
    "    df[\"Datum\"] = pd.to_datetime(df[\"Datum\"], errors=\"coerce\").dt.normalize()\n",
    "    df.dropna(subset=[\"Datum\"], inplace=True)\n",
    "\n",
    "    # Drop duplicate date columns if exist\n",
    "    if \"date\" in df.columns:\n",
    "        df.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "df_sales.info(), df_weather.info(), df_umsatz.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding suffixes helps avoid confusion during merging\n",
    "\n",
    "df_sales = df_sales.add_suffix(\"_sales\")\n",
    "df_sales.rename(columns={\"Datum_sales\": \"Datum\"}, inplace=True)\n",
    "\n",
    "df_weather = df_weather.add_suffix(\"_weather\")\n",
    "df_weather.rename(columns={\"Datum_weather\": \"Datum\"}, inplace=True)\n",
    "\n",
    "df_umsatz = df_umsatz.add_suffix(\"_umsatz\")\n",
    "df_umsatz.rename(columns={\"Datum_umsatz\": \"Datum\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (\n",
    "    df_sales\n",
    "    .merge(df_weather, on=\"Datum\", how=\"outer\")\n",
    "    .merge(df_umsatz, on=\"Datum\", how=\"outer\")\n",
    ")\n",
    "\n",
    "merged_df.shape\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f05e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric summary\n",
    "merged_df.describe()\n",
    "\n",
    "# For all columns (including categorical)\n",
    "merged_df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = merged_df.isna().sum()\n",
    "missing_percent = (merged_df.isna().sum() / len(merged_df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    \"Missing Count\": missing_count,\n",
    "    \"Missing %\": missing_percent\n",
    "})\n",
    "\n",
    "missing_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471abb4d",
   "metadata": {},
   "source": [
    "### âœ”ï¸ Missing Value Strategy\n",
    "\n",
    "**Umsatz (Sales):**\n",
    "- Missing values mean the day has **no sales** or is **outside the bakery event period**.\n",
    "- These rows should be **removed**, not imputed.\n",
    "\n",
    "**Weather Variables:**\n",
    "- Weather data may be missing because not all dates have weather records.\n",
    "- Fill missing values using interpolation (numerical)  \n",
    "  and assign -1 for Wettercode to indicate â€œunknown weatherâ€.\n",
    "\n",
    "**Kiwo Event Flag:**\n",
    "- If missing â†’ fill with 0 (day outside event).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = merged_df.copy()\n",
    "\n",
    "# Remove rows where sales are missing\n",
    "clean_df = clean_df.dropna(subset=[\"Umsatz_umsatz\"])\n",
    "\n",
    "# Fill missing Wettercode with category -1\n",
    "if \"Wettercode_weather\" in clean_df.columns:\n",
    "    clean_df[\"Wettercode_weather\"] = clean_df[\"Wettercode_weather\"].fillna(-1)\n",
    "\n",
    "# Interpolate numerical weather values\n",
    "for col in clean_df.columns:\n",
    "    if (\"_weather\" in col) and (clean_df[col].dtype in [\"float64\", \"int64\"]):\n",
    "        clean_df[col] = clean_df[col].interpolate()\n",
    "\n",
    "clean_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"KielerWoche_sales\"] = clean_df[\"KielerWoche_sales\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcdfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop wettercode_weather column\n",
    "df_no_weather_code = clean_df.drop(columns=[\"Wettercode_weather\"])\n",
    "df_no_weather_code.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76d324",
   "metadata": {},
   "source": [
    "## Adding extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_weather_code['Datum'] = pd.to_datetime(df_no_weather_code['Datum'], errors='coerce').dt.normalize()\n",
    "n_invalid = df_no_weather_code['Datum'].isna().sum()\n",
    "if n_invalid > 0:\n",
    "    print(f\"Warning: {n_invalid} rows have invalid 'Datum' and will have NaT in day columns. Sample:\")\n",
    "    display(df_no_weather_code[df_no_weather_code['Datum'].isna()].head())\n",
    "\n",
    "# Create integer and name columns for day of week\n",
    "df_no_weather_code['day_of_week'] = df_no_weather_code['Datum'].dt.weekday  # Monday=0 .. Sunday=6\n",
    "df_no_weather_code['day'] = df_no_weather_code['Datum'].dt.day_name()\n",
    "\n",
    "# Optional: make 'day' categorical ordered Monday..Sunday\n",
    "ordered_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df_no_weather_code['day'] = pd.Categorical(df_no_weather_code['day'], categories=ordered_days, ordered=True)\n",
    "\n",
    "print(\"\\nCounts per weekday:\")\n",
    "print(df_no_weather_code['day'].value_counts().sort_index())\n",
    "df_no_weather_code.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c754c",
   "metadata": {},
   "source": [
    "### Adding more weather data from meteo archive api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89809343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, date, timedelta\n",
    "import time\n",
    "from typing import Union, Iterable, Dict, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Simple in-memory cache for API responses\n",
    "try:\n",
    "    _OPEN_METEO_CACHE\n",
    "except NameError:\n",
    "    _OPEN_METEO_CACHE: Dict[str, Dict[str, float]] = {}\n",
    "\n",
    "def _iso_date(d: Union[str, date, datetime]) -> str:\n",
    "    if isinstance(d, str):\n",
    "        return datetime.fromisoformat(d).date().isoformat()\n",
    "    if isinstance(d, datetime):\n",
    "        return d.date().isoformat()\n",
    "    return d.isoformat()\n",
    "\n",
    "def fetch_open_meteo_daily_range(\n",
    "    start_date: Union[str, date, datetime],\n",
    "    end_date: Union[str, date, datetime],\n",
    "    latitude: float = 54.3233,\n",
    "    longitude: float = 10.1228,\n",
    "    timezone: str = \"Europe/Berlin\",\n",
    "    daily_vars: List[str] = None,\n",
    "    max_retries: int = 3,\n",
    "    timeout: float = 15.0,\n",
    "    use_cache: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch daily historical variables from Open-Meteo archive API for a given inclusive date range.\n",
    "    By default uses Kiel coordinates (lat=54.3233, lon=10.1228).\n",
    "    daily_vars example: ['precipitation_hours', 'sunshine_duration', 'rain_sum']\n",
    "    Returns a pandas.DataFrame indexed by date (datetime.date) with columns named after daily_vars.\n",
    "    \"\"\"\n",
    "    if daily_vars is None:\n",
    "        daily_vars = ['precipitation_hours', 'sunshine_duration', 'rain_sum']\n",
    "\n",
    "    start_iso = _iso_date(start_date)\n",
    "    end_iso = _iso_date(end_date)\n",
    "    start_dt = datetime.fromisoformat(start_iso).date()\n",
    "    end_dt = datetime.fromisoformat(end_iso).date()\n",
    "    if end_dt < start_dt:\n",
    "        raise ValueError(\"end_date must be >= start_date\")\n",
    "\n",
    "    # Build cache key based on parameters and requested range\n",
    "    key = f\"{latitude:.6f}_{longitude:.6f}_{start_iso}_{end_iso}_{','.join(daily_vars)}_{timezone}\"\n",
    "    if use_cache and key in _OPEN_METEO_CACHE:\n",
    "        df = _OPEN_METEO_CACHE[key].copy()\n",
    "        return df\n",
    "\n",
    "    base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": start_iso,\n",
    "        \"end_date\": end_iso,\n",
    "        \"daily\": \",\".join(daily_vars),\n",
    "        \"timezone\": timezone\n",
    "    }\n",
    "\n",
    "    last_exc = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            r = requests.get(base_url, params=params, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            daily = data.get(\"daily\", {})\n",
    "            times = daily.get(\"time\", []) or []\n",
    "            if not times:\n",
    "                raise ValueError(\"No 'time' in API response daily block.\")\n",
    "            results = {\"date\": pd.to_datetime(times).date}\n",
    "            for v in daily_vars:\n",
    "                vals = daily.get(v, None)\n",
    "                if vals is None:\n",
    "                    # If a requested variable is missing, fill with NaN\n",
    "                    results[v] = [np.nan] * len(times)\n",
    "                else:\n",
    "                    # Convert to numeric (floats), keep NaN if parsing fails\n",
    "                    results[v] = [float(x) if x is not None else np.nan for x in vals]\n",
    "            df = pd.DataFrame(results, index=pd.to_datetime(times).date)\n",
    "            df.index.name = \"date\"\n",
    "            df = df[[v for v in daily_vars]]  # ensure column order\n",
    "            if use_cache:\n",
    "                _OPEN_METEO_CACHE[key] = df.copy()\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(0.5 * attempt)\n",
    "                continue\n",
    "            raise RuntimeError(f\"Failed fetching Open-Meteo archive: {e}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = df_no_weather_code['Datum'].min()\n",
    "max_date = df_no_weather_code['Datum'].max()\n",
    "##min_date = \"2013-07-01\"\n",
    "##max_date = \"2014-07-30\"\n",
    "print (f\"Fetching weather data from {min_date} to {max_date}...\")\n",
    "lat_kiel, lon_kiel = 54.3233, 10.1228\n",
    "daily_vars = ['precipitation_hours', 'sunshine_duration', 'rain_sum','temperature_2m_mean']\n",
    "df_extra_weather = fetch_open_meteo_daily_range(min_date, max_date, latitude=lat_kiel, longitude=lon_kiel, daily_vars=daily_vars)\n",
    "# print columns of df_extended_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra_weather['sunshine_hours'] = df_extra_weather['sunshine_duration'] / 3600.0\n",
    "#df_extended_weather.head()\n",
    "\n",
    "# print row count for df_extended_weather and df_no_weather_code\n",
    "print(f\"Extended Weather Data Rows: {len(df_extra_weather)}\")\n",
    "print(f\"Sales Data Rows: {len(df_no_weather_code)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac1577",
   "metadata": {},
   "source": [
    "### Extended Data Frames\n",
    "Its with extra weather data from open meteo api: df_merged_extended_weather\n",
    "with rolling 7 day average as well for umsatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "841cb25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame Rows: 9334\n",
      "Merged DataFrame Shape: (9334, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>KielerWoche_sales</th>\n",
       "      <th>Bewoelkung_weather</th>\n",
       "      <th>Temperatur_weather</th>\n",
       "      <th>Windgeschwindigkeit_weather</th>\n",
       "      <th>id_umsatz</th>\n",
       "      <th>Warengruppe_umsatz</th>\n",
       "      <th>Umsatz_umsatz</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>precipitation_hours</th>\n",
       "      <th>sunshine_duration</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>sunshine_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1307011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148.828353</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31025.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.618242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1307012.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>535.856285</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31025.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.618242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1307013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.198426</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31025.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.618242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1307014.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.890169</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31025.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.618242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1307015.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>317.475875</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31025.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.618242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Datum  KielerWoche_sales  Bewoelkung_weather  Temperatur_weather  \\\n",
       "394 2013-07-01                0.0                 6.0             17.8375   \n",
       "395 2013-07-01                0.0                 6.0             17.8375   \n",
       "396 2013-07-01                0.0                 6.0             17.8375   \n",
       "397 2013-07-01                0.0                 6.0             17.8375   \n",
       "398 2013-07-01                0.0                 6.0             17.8375   \n",
       "\n",
       "     Windgeschwindigkeit_weather  id_umsatz  Warengruppe_umsatz  \\\n",
       "394                         15.0  1307011.0                 1.0   \n",
       "395                         15.0  1307012.0                 2.0   \n",
       "396                         15.0  1307013.0                 3.0   \n",
       "397                         15.0  1307014.0                 4.0   \n",
       "398                         15.0  1307015.0                 5.0   \n",
       "\n",
       "     Umsatz_umsatz  day_of_week     day  precipitation_hours  \\\n",
       "394     148.828353            0  Monday                  7.0   \n",
       "395     535.856285            0  Monday                  7.0   \n",
       "396     201.198426            0  Monday                  7.0   \n",
       "397      65.890169            0  Monday                  7.0   \n",
       "398     317.475875            0  Monday                  7.0   \n",
       "\n",
       "     sunshine_duration  rain_sum  temperature_2m_mean  sunshine_hours  \n",
       "394           31025.67       1.0                 15.6        8.618242  \n",
       "395           31025.67       1.0                 15.6        8.618242  \n",
       "396           31025.67       1.0                 15.6        8.618242  \n",
       "397           31025.67       1.0                 15.6        8.618242  \n",
       "398           31025.67       1.0                 15.6        8.618242  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra_weather.index = pd.to_datetime(df_extra_weather.index)\n",
    "df_merged_extended_weather = df_no_weather_code.merge(\n",
    "    df_extra_weather,\n",
    "    left_on='Datum',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged DataFrame Rows: {len(df_merged_extended_weather)}\")\n",
    "print(f\"Merged DataFrame Shape: {df_merged_extended_weather.shape}\")\n",
    "df_merged_extended_weather.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
